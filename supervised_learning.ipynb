{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39796ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NOTE: This code assumes the following variables have been correctly defined \n",
    "# and populated from previous steps:\n",
    "# X_train_fs, X_test_fs (Feature-selected scaled features)\n",
    "# y_train, y_test (Target variable arrays)\n",
    "\n",
    "# =========================================================================\n",
    "# 1. DATA FIX: ENSURE TARGET VARIABLES ARE ROBUST 1D INTEGERS\n",
    "#    This is the definitive fix to ensure arrays are strictly binary (0 or 1).\n",
    "\n",
    "# Ensure y arrays are simple 1D integer arrays and convert to numpy for robustness\n",
    "y_train = np.ravel(y_train).astype(int)\n",
    "y_test = np.ravel(y_test).astype(int)\n",
    "\n",
    "# =========================================================================\n",
    "# 2. MODEL SETUP\n",
    "\n",
    "\n",
    "# Dictionary of all models to train\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(solver='liblinear', random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    # SVM needs probability=True for ROC curve generation\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42, probability=True)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "print(\"--- Supervised Model Training and Evaluation ---\")\n",
    "\n",
    "# =========================================================================\n",
    "# 3. TRAINING AND EVALUATION LOOP (FINAL ROBUST FIX)\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 3a. Train the model on Feature Selected Data\n",
    "    model.fit(X_train_fs, y_train)\n",
    "\n",
    "    # 3b. Make predictions and get probabilities\n",
    "    y_pred = model.predict(X_test_fs)\n",
    "    \n",
    "    # Get probability scores for the ROC Curve (needed for AUC)\n",
    "    y_proba = model.predict_proba(X_test_fs)[:, 1]\n",
    "\n",
    "    # 3c. Evaluate metrics (using 'weighted' average as it is robust against\n",
    "    # the false multiclass detection error)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Use 'weighted' average to resolve the multiclass ValueError \n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # 3d. Store results\n",
    "    results[name] = {\n",
    "        'Accuracy': f'{accuracy:.4f}',\n",
    "        'Precision': f'{precision:.4f}',\n",
    "        'Recall': f'{recall:.4f}',\n",
    "        'F1-Score': f'{f1:.4f}'\n",
    "    }\n",
    "\n",
    "    # 3e. Generate ROC Curve and AUC Score\n",
    "    \n",
    "    # Check for unexpected labels and filter the data if necessary.\n",
    "    # We create a filter mask to ensure only 0s and 1s are processed.\n",
    "    valid_indices = np.isin(y_test, [0, 1])\n",
    "    y_test_filtered = y_test[valid_indices]\n",
    "    y_proba_filtered = y_proba[valid_indices]\n",
    "    \n",
    "    # Final robust call for roc_curve on the filtered data\n",
    "    fpr, tpr, _ = roc_curve(y_test_filtered, y_proba_filtered)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC Curve\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "    print(f\"âœ… Trained and evaluated {name}. AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# =========================================================================\n",
    "# 4. FINAL VISUALIZATION AND SUMMARY\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Baseline (AUC = 0.50)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Display all performance metrics in a DataFrame\n",
    "print(\"\\n--- Performance Metrics Summary ---\")\n",
    "performance_df = pd.DataFrame(results).T\n",
    "print(performance_df)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
