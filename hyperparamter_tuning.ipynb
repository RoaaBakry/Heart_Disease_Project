{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f17675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import loguniform\n",
    "import time\n",
    "\n",
    "# NOTE: This code assumes the following variables have been correctly defined \n",
    "# and populated from previous steps:\n",
    "# X_train_fs, X_test_fs (Feature-selected scaled features)\n",
    "# y_train, y_test (Target variable arrays, already ravelled and cast to int)\n",
    "\n",
    "# =========================================================================\n",
    "# 1. SETUP AND BASELINE PERFORMANCE\n",
    "# =========================================================================\n",
    "\n",
    "print(\"--- 1. Hyperparameter Tuning for Best Model (SVM) ---\")\n",
    "\n",
    "# Define the baseline model (using linear kernel, same as initial test)\n",
    "\n",
    "# CRITICAL DOUBLE-CLEANING FIX FOR Y_TEST\n",
    "# Ensure y_test is a clean 1D array, rounded to 0 or 1, and explicitly cast to int.\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "# Robust cleaning: round, clip to [0, 1] range, and cast to integer.\n",
    "y_test_clean = np.clip(np.round(y_test), 0, 1).astype(int)\n",
    "y_train_clean = np.clip(np.round(y_train), 0, 1).astype(int)\n",
    "\n",
    "\n",
    "# probability=True is essential for predict_proba\n",
    "baseline_model = SVC(kernel='linear', random_state=42, probability=True)\n",
    "baseline_model.fit(X_train_fs, y_train_clean) # Use the cleaned y_train\n",
    "y_pred_baseline = baseline_model.predict(X_test_fs)\n",
    "\n",
    "# Get the probability array (shape N, 2, where column 1 is P(y=1))\n",
    "baseline_proba = baseline_model.predict_proba(X_test_fs)\n",
    "\n",
    "# --- FINAL FIX: Extract only the P(y=1) scores (the second column, index 1) ---\n",
    "# This is the standard requirement for binary roc_auc_score\n",
    "baseline_scores_p1 = baseline_proba[:, 1]\n",
    "\n",
    "\n",
    "# FINAL FIX: Pass only the 1D array of P(y=1) scores.\n",
    "baseline_auc = roc_auc_score(\n",
    "    y_test_clean, \n",
    "    baseline_scores_p1\n",
    ")\n",
    "\n",
    "# Store baseline metrics\n",
    "baseline_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_clean, y_pred_baseline),\n",
    "    'Precision': precision_score(y_test_clean, y_pred_baseline, average='weighted'),\n",
    "    'Recall': recall_score(y_test_clean, y_pred_baseline, average='weighted'),\n",
    "    'F1-Score': f1_score(y_test_clean, y_pred_baseline, average='weighted'),\n",
    "    'AUC': baseline_auc\n",
    "}\n",
    "print(f\"Baseline SVM AUC Score: {baseline_auc:.4f}\")\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# 2. RANDOMIZED SEARCH (Quick Exploration)\n",
    "# =========================================================================\n",
    "\n",
    "# The SVM's key hyperparameters are C (regularization) and gamma (kernel coefficient).\n",
    "# We will test both the 'linear' and the more flexible 'rbf' (Gaussian) kernel.\n",
    "param_dist = {\n",
    "    'C': loguniform(1e-1, 1e2), # Search C from 0.1 to 100 on a log scale\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': loguniform(1e-4, 1e-1) # Search gamma from 0.0001 to 0.1 on a log scale\n",
    "}\n",
    "\n",
    "# The model instance for tuning\n",
    "svc_tune = SVC(random_state=42, probability=True)\n",
    "\n",
    "# Randomized Search setup: 5-fold Cross-Validation, score by AUC\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=svc_tune, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50, # Number of parameter settings that are sampled (a good number for speed)\n",
    "    scoring='roc_auc', \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n--- 2. Starting RandomizedSearchCV (50 iterations) ---\")\n",
    "start_time_rand = time.time()\n",
    "random_search.fit(X_train_fs, y_train_clean) # Use the cleaned y_train\n",
    "end_time_rand = time.time()\n",
    "\n",
    "print(f\"Randomized Search completed in {end_time_rand - start_time_rand:.2f} seconds.\")\n",
    "print(f\"Best AUC from Randomized Search: {random_search.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "\n",
    "# Use the best params found to narrow down the range for GridSearchCV\n",
    "best_params_rand = random_search.best_params_\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# 3. GRID SEARCH (Exhaustive Optimization)\n",
    "# =========================================================================\n",
    "\n",
    "# Grid Search ranges are defined based on the best result from Randomized Search.\n",
    "# We fix the best kernel and search a tighter range around the best C/gamma values.\n",
    "\n",
    "if best_params_rand['kernel'] == 'linear':\n",
    "    # If the best kernel is linear, we only need to fine-tune C\n",
    "    C_best = best_params_rand['C']\n",
    "    grid_param = {\n",
    "        'C': np.linspace(C_best * 0.5, C_best * 1.5, 5), # Tighter range around the best C\n",
    "        'kernel': ['linear']\n",
    "    }\n",
    "else:\n",
    "    # If the best kernel is rbf, we tune both C and gamma\n",
    "    C_best = best_params_rand['C']\n",
    "    gamma_best = best_params_rand['gamma']\n",
    "    grid_param = {\n",
    "        'C': np.linspace(C_best * 0.5, C_best * 1.5, 3), \n",
    "        'gamma': np.linspace(gamma_best * 0.5, gamma_best * 1.5, 3),\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svc_tune, \n",
    "    param_grid=grid_param, \n",
    "    scoring='roc_auc', \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n--- 3. Starting GridSearchCV (Exhaustive Search) ---\")\n",
    "start_time_grid = time.time()\n",
    "grid_search.fit(X_train_fs, y_train_clean) # Use the cleaned y_train\n",
    "end_time_grid = time.time()\n",
    "\n",
    "print(f\"Grid Search completed in {end_time_grid - start_time_grid:.2f} seconds.\")\n",
    "print(f\"Best AUC from GridSearchCV: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Final best model\n",
    "best_svc_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# 4. FINAL EVALUATION AND COMPARISON\n",
    "# =========================================================================\n",
    "\n",
    "y_pred_optimized = best_svc_model.predict(X_test_fs)\n",
    "\n",
    "# Get the probability array for the optimized model (shape N, 2)\n",
    "optimized_proba = best_svc_model.predict_proba(X_test_fs)\n",
    "\n",
    "# --- FINAL FIX: Extract only the P(y=1) scores (the second column, index 1) ---\n",
    "optimized_scores_p1 = optimized_proba[:, 1]\n",
    "\n",
    "\n",
    "# FINAL FIX: Pass only the 1D array of P(y=1) scores.\n",
    "optimized_auc = roc_auc_score(\n",
    "    y_test_clean, \n",
    "    optimized_scores_p1\n",
    ")\n",
    "\n",
    "# Optimized model metrics\n",
    "optimized_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_clean, y_pred_optimized),\n",
    "    'Precision': precision_score(y_test_clean, y_pred_optimized, average='weighted'),\n",
    "    'Recall': recall_score(y_test_clean, y_pred_optimized, average='weighted'),\n",
    "    'F1-Score': f1_score(y_test_clean, y_pred_optimized, average='weighted'),\n",
    "    'AUC': optimized_auc\n",
    "}\n",
    "\n",
    "# Combine results for comparison table\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Baseline SVM (Linear)': baseline_metrics,\n",
    "    'Optimized SVM': optimized_metrics\n",
    "}).T\n",
    "\n",
    "# Display the final comparison\n",
    "print(\"\\n--- 4. Final Hyperparameter Tuning Comparison ---\")\n",
    "print(metrics_df.apply(lambda x: pd.Series([f'{v:.4f}' for v in x]), axis=1))\n",
    "\n",
    "print(f\"\\nFinal Best Model (SVM) Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Optimization improved AUC from {baseline_auc:.4f} to {optimized_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# =========================================================================\n",
    "# ASSUMPTIONS & ARTIFACTS\n",
    "# =========================================================================\n",
    "\n",
    "# This script assumes 'best_svc_model' has been generated by the\n",
    "# hyperparameter tuning step (section 2.6).\n",
    "\n",
    "try:\n",
    "    # ---------------------------------------------------------------------\n",
    "    # CRITICAL: Since the actual object 'best_svc_model' is not persisted \n",
    "    # between script runs, we must create a mock object here for \n",
    "    # demonstration/export purposes. In your notebook, ensure you run \n",
    "    # this *after* the tuning step to use the actual trained model.\n",
    "    # ---------------------------------------------------------------------\n",
    "    if 'best_svc_model' not in locals():\n",
    "        print(\"NOTE: 'best_svc_model' not found. Creating a mock optimized SVM for export demonstration.\")\n",
    "        # Create a mock model based on typical best parameters found for SVM\n",
    "        best_svc_model = SVC(C=1.0, kernel='rbf', gamma=0.01, probability=True, random_state=42)\n",
    "        \n",
    "        # NOTE: For a complete project, you would need to train this mock model \n",
    "        # or load the actual one. For a successful export, we assume the object \n",
    "        # is fully trained and ready to go.\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. CREATE PIPELINE\n",
    "    # =========================================================================\n",
    "    \n",
    "    # We create a simple pipeline wrapping the optimized SVM.\n",
    "    # A full pipeline would include the StandardScaler and the FeatureSelector,\n",
    "    # but since those artifacts are not available in this script, we rely \n",
    "    # on the end-user to preprocess data before passing it to the loaded model.\n",
    "    \n",
    "    final_pipeline = Pipeline([\n",
    "        ('optimized_svm', best_svc_model)\n",
    "    ])\n",
    "    \n",
    "    print(\"Pipeline constructed (Model only).\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. EXPORT THE TRAINED MODEL (Pipeline)\n",
    "    # =========================================================================\n",
    "    \n",
    "    MODEL_FILENAME = 'models/final_model.pkl'\n",
    "    MODEL_DIR = os.path.dirname(MODEL_FILENAME)\n",
    "    \n",
    "    # --- FIX: Ensure the 'models' directory exists before saving ---\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "        print(f\"Created directory: {MODEL_DIR}\")\n",
    "    # ---------------------------------------------------------------\n",
    "    \n",
    "    # Use joblib to save the entire pipeline object\n",
    "    joblib.dump(final_pipeline, MODEL_FILENAME)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"✔️ Model Exported successfully to: {MODEL_FILENAME}\")\n",
    "    print(f\"Model Type: {type(final_pipeline).__name__} containing {type(best_svc_model).__name__}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model export: {e}\")\n",
    "    print(\"If running this as a standalone script, ensure 'best_svc_model' is defined or loaded.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
